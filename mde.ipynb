{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e45c131",
   "metadata": {},
   "source": [
    "## Monocular Depth Estimation Project\n",
    "\n",
    "This file will follow the full training and evaluation process, report results across experiments, and visualize results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bd3a317",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from DPT.dpt.models import DPTDepthModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from dataloaders.nyu_data import NyuDepthV2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, Optimizer\n",
    "from losses.mde_losses import ScaleAndShiftInvariantLoss\n",
    "from losses.LMR import LMRLoss\n",
    "from LNRegularizer.LNR import LNR\n",
    "from torchvision.transforms import v2\n",
    "from typing import Dict\n",
    "from tqdm.notebook import tqdm\n",
    "# functions for displaying results\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7113efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets\n",
    "NYU_DATA_PATH = \"data/nyu_data/nyu_depth_v2_labeled.mat\"\n",
    "\n",
    "# download from http://horatio.cs.nyu.edu/mit/silberman/indoor_seg_sup/splits.mat\n",
    "NYU_SPLIT_PATH = \"data/nyu_data/splits.mat\"\n",
    "\n",
    "nyu_test_ds = NyuDepthV2(NYU_DATA_PATH, NYU_SPLIT_PATH, split=\"test\")\n",
    "nyu_train_ds = NyuDepthV2(NYU_DATA_PATH, NYU_SPLIT_PATH, split=\"train\")\n",
    "nyu_train_dataloader = DataLoader(nyu_train_ds, batch_size=12)\n",
    "nyu_test_dataloader = DataLoader(nyu_train_ds, batch_size=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9709b9",
   "metadata": {},
   "source": [
    "## Training Functions\n",
    "\n",
    "Moving everything to a single notebook simplifies kernel issues and modifying portions of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1146f6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_simple(\n",
    "    model: nn.Module,\n",
    "    loader: DataLoader,\n",
    "    optim: Optimizer,\n",
    "    epochs: int = 50,\n",
    "    print_every: int = 1,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Train depth head on NYU dataset with no additional regularization\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    pbar = tqdm(total=epochs * len(loader), desc=\"Training MDE:\")\n",
    "    i = 0\n",
    "    # loss function\n",
    "    loss = ScaleAndShiftInvariantLoss()\n",
    "\n",
    "    # training loop\n",
    "    for _ in range(epochs):\n",
    "        for batch in loader:\n",
    "            X = batch[\"image\"].float().to(\"mps\")\n",
    "            y = batch[\"depth\"].float().to(\"mps\")\n",
    "            mask = batch[\"mask\"].float().to(\"mps\")\n",
    "\n",
    "            X = X.permute(0, 3, 1, 2)\n",
    "\n",
    "            # calculate depth\n",
    "            prediction = model(X)\n",
    "\n",
    "            # calculate losses\n",
    "            err = loss(prediction, y, mask)\n",
    "            mse_loss = F.mse_loss(prediction, y)\n",
    "            l1_loss = F.smooth_l1_loss(prediction, y)\n",
    "\n",
    "            composite_loss = (2 * err) + (0.5 * mse_loss) + (0.1 * l1_loss)\n",
    "\n",
    "            # print(f\"composite_loss requires_grad: {composite_loss.requires_grad}\")\n",
    "\n",
    "            # process optimizer\n",
    "            optim.zero_grad()\n",
    "            composite_loss.backward()  # back-prop losses\n",
    "            optim.step()\n",
    "\n",
    "            # debugging\n",
    "            grads = []\n",
    "            for name, p in model.named_parameters():\n",
    "                if p.grad is not None:\n",
    "                    grads.append(p.grad.norm().item())\n",
    "                else:\n",
    "                    pass\n",
    "                    # print(f\"{name} gradient is none\")\n",
    "\n",
    "            grads = torch.Tensor(grads)\n",
    "\n",
    "            if i % print_every == 0:\n",
    "                with torch.no_grad():\n",
    "                    mse_loss = F.mse_loss(prediction, y)\n",
    "                pbar.set_postfix_str(\n",
    "                    f\"train_loss: {err:.2f} | mse_loss: {mse_loss:.2f} | l1_loss: {l1_loss:.2f} | composite loss: {composite_loss:.2f} | Average gradient: {grads.mean()} | min grad: {grads.min()} | max grad {grads.max().item():.2f} | min pred. depth: {prediction.min().item():.2f} | max pred. depth: {prediction.max().item():.2f}\"\n",
    "                )\n",
    "                pbar.update(print_every)\n",
    "\n",
    "            i += 1\n",
    "\n",
    "\n",
    "def train_with_lmr(\n",
    "    model: nn.Module,\n",
    "    loader: DataLoader,\n",
    "    optim: Optimizer,\n",
    "    epochs: int = 50,\n",
    "    print_every: int = 1,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Train depth head on NYU dataset with lmr regularizer\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    pbar = tqdm(total=epochs * len(loader), desc=\"Training MDE:\")\n",
    "    i = 0\n",
    "    # loss function\n",
    "    loss = ScaleAndShiftInvariantLoss()\n",
    "    lmr_loss = LMRLoss()\n",
    "\n",
    "    # training loop\n",
    "    for _ in range(epochs):\n",
    "        for batch in loader:\n",
    "            X = batch[\"image\"].float().to(\"mps\")\n",
    "            y = batch[\"depth\"].float().to(\"mps\")\n",
    "            mask = batch[\"mask\"].float().to(\"mps\")\n",
    "\n",
    "            X = X.permute(0, 3, 1, 2)\n",
    "\n",
    "            # pass input through LMR model\n",
    "            output_mask = LNR(X)\n",
    "\n",
    "            # calculate depth\n",
    "            prediction = model(X)\n",
    "\n",
    "            # calculate losses\n",
    "            err = loss(prediction, y, mask)\n",
    "            lmr_mask_loss = lmr_loss(\n",
    "                net_mask=output_mask, depth_hat=prediction.detach(), depth=y, k=100\n",
    "            )\n",
    "\n",
    "            err = err + lmr_mask_loss  # combine losses\n",
    "\n",
    "            # process optimizer\n",
    "            optim.zero_grad()\n",
    "            err.backward()  # back-prop losses\n",
    "            optim.step()\n",
    "\n",
    "            if i % print_every == 0:\n",
    "                with torch.no_grad():\n",
    "                    mse_loss = F.mse_loss(prediction, y)\n",
    "                pbar.set_postfix_str(\n",
    "                    f\"train_loss: {err:.2f} | mse_loss: {mse_loss:.2f}\"\n",
    "                )\n",
    "                pbar.update(print_every)\n",
    "\n",
    "            i += 1\n",
    "\n",
    "\n",
    "def train_with_cutmix(\n",
    "    model: nn.Module,\n",
    "    loader: DataLoader,\n",
    "    optim: Optimizer,\n",
    "    epochs: int = 50,\n",
    "    print_every: int = 1,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Train depth head on NYU dataset using cutmix regularization\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    pbar = tqdm(total=epochs * len(loader), desc=\"Training MDE:\")\n",
    "    i = 0\n",
    "    # loss function\n",
    "    loss = ScaleAndShiftInvariantLoss()\n",
    "    lmr_loss = LMRLoss()\n",
    "\n",
    "    # cutmix transform\n",
    "    cutmix = v2.CutMix()\n",
    "\n",
    "    # training loop\n",
    "    for _ in range(epochs):\n",
    "        for batch in loader:\n",
    "            X = batch[\"image\"].float().to(\"mps\")\n",
    "            y = batch[\"depth\"].float().to(\"mps\")\n",
    "            mask = batch[\"mask\"].float().to(\"mps\")\n",
    "\n",
    "            X = X.permute(0, 3, 1, 2)\n",
    "\n",
    "            # apply cutmix to batch\n",
    "            X, y = cutmix(X, y)\n",
    "\n",
    "            # calculate depth\n",
    "            prediction = model(X)\n",
    "\n",
    "            # calculate losses\n",
    "            err = loss(prediction, y, mask)\n",
    "            # process optimizer\n",
    "            optim.zero_grad()\n",
    "            err.backward()  # back-prop losses\n",
    "            optim.step()\n",
    "\n",
    "            if i % print_every == 0:\n",
    "                with torch.no_grad():\n",
    "                    mse_loss = F.mse_loss(prediction, y)\n",
    "                pbar.set_postfix_str(\n",
    "                    f\"train_loss: {err:.2f} | mse_loss: {mse_loss:.2f}\"\n",
    "                )\n",
    "                pbar.update(print_every)\n",
    "\n",
    "            i += 1\n",
    "\n",
    "\n",
    "def eval(model: nn.Module, loader: DataLoader) -> Dict:\n",
    "    \"\"\"\n",
    "    assess the accuracy of the model\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    pbar = tqdm(total=len(loader), desc=\"Evaluating MDE:\")\n",
    "    test_err = []\n",
    "    for batch in loader:\n",
    "        X = batch[\"image\"].float().to(\"mps\")\n",
    "        y = batch[\"depth\"].float().to(\"mps\")\n",
    "        with torch.no_grad():\n",
    "            X = X.permute(0, 3, 1, 2)\n",
    "            prediction = model(X)\n",
    "            err = F.mse_loss(\n",
    "                prediction, y\n",
    "            )  # when looking at error for evaluation use MSE loss\n",
    "            test_err.append(err)\n",
    "\n",
    "        # process optimizer\n",
    "        pbar.set_postfix_str(f\"mse_loss: {err:.2f}\")\n",
    "        pbar.update(1)\n",
    "\n",
    "    print(f\"Average MSE Loss: {sum(test_err)/len(test_err)}\")\n",
    "    return {\"mse_avg\": sum(test_err) / len(test_err)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2fe46cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_test_frames(model: nn.Module, dataset: Dataset, indices: List[int]) -> None:\n",
    "    \"\"\"Generate a plot of depth images at specific indices\"\"\"\n",
    "    for i in indices:\n",
    "        datapoint = dataset[i]\n",
    "        X = datapoint[\"image\"]\n",
    "        y = datapoint[\"depth\"]\n",
    "        mask = datapoint[\"mask\"]\n",
    "\n",
    "        fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(10, 8))\n",
    "        ax1.imshow(X)\n",
    "        ax1.set_title(\"Image\")\n",
    "        ax2.imshow(y)\n",
    "        ax2.set_title(\"Truth depth\")\n",
    "\n",
    "        X = torch.Tensor(X).to(\"mps\").unsqueeze(0).permute(0, 3, 1, 2)\n",
    "        with torch.no_grad():\n",
    "            prediction = model(X).permute(1, 2, 0).cpu().numpy()\n",
    "        ax3.imshow(prediction, cmap=\"viridis\")\n",
    "        # ax3.title(\"Predicted depth\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab9a0b7",
   "metadata": {},
   "source": [
    "#### Experiments\n",
    "\n",
    "Each experiment will use a separate model so that the results can be compared directly in later sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5ebf684",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michael/Documents/Grad_School/Fall25/DeepLearning/Project/MDE/.venv/lib/python3.13/site-packages/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name vit_base_resnet50_384 to current vit_base_r50_s16_384.orig_in21k_ft_in1k.\n",
      "  model = create_fn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "442ecfc939e44e599da1a2eb4d536869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training MDE::   0%|          | 0/67 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "composite_loss requires_grad: True\n",
      "composite_loss requires_grad: True\n",
      "composite_loss requires_grad: True\n",
      "composite_loss requires_grad: True\n",
      "composite_loss requires_grad: True\n",
      "composite_loss requires_grad: True\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m optim = Adam(simple_model.named_parameters(), lr=\u001b[32m1e-6\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# standard training - no regularization at all\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[43mtrain_simple\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43msimple_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnyu_train_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptim\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m simple_res = \u001b[38;5;28meval\u001b[39m(simple_model, nyu_test_dataloader)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mtrain_simple\u001b[39m\u001b[34m(model, loader, optim, epochs, print_every)\u001b[39m\n\u001b[32m     24\u001b[39m X = X.permute(\u001b[32m0\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m)\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# calculate depth\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m prediction = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# calculate losses\u001b[39;00m\n\u001b[32m     30\u001b[39m err = loss(prediction, y, mask)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Grad_School/Fall25/DeepLearning/Project/MDE/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Grad_School/Fall25/DeepLearning/Project/MDE/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Grad_School/Fall25/DeepLearning/Project/MDE/DPT/dpt/models.py:119\u001b[39m, in \u001b[36mDPTDepthModel.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    117\u001b[39m     depth = \u001b[38;5;28mself\u001b[39m.scale * inv_depth + \u001b[38;5;28mself\u001b[39m.shift\n\u001b[32m    118\u001b[39m     depth[depth < \u001b[32m1e-8\u001b[39m] = \u001b[32m1e-8\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     depth = \u001b[32;43m1.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\n\u001b[32m    120\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m depth\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Grad_School/Fall25/DeepLearning/Project/MDE/.venv/lib/python3.13/site-packages/torch/_tensor.py:38\u001b[39m, in \u001b[36m_handle_torch_function_and_wrap_type_error_to_not_implemented.<locals>.wrapped\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_handle_torch_function_and_wrap_type_error_to_not_implemented\u001b[39m(\n\u001b[32m     36\u001b[39m     f: Callable[Concatenate[_TensorLike, _P], \u001b[33m\"\u001b[39m\u001b[33mTensor\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     37\u001b[39m ) -> Callable[Concatenate[_TensorLike, _P], \u001b[33m\"\u001b[39m\u001b[33mTensor\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     \u001b[38;5;129m@functools\u001b[39m.wraps(f)\n\u001b[32m     39\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m: _TensorLike, *args: _P.args, **kwargs: _P.kwargs) -> \u001b[33m\"\u001b[39m\u001b[33mTensor\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     40\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     41\u001b[39m             \u001b[38;5;66;03m# See https://github.com/pytorch/pytorch/issues/75462\u001b[39;00m\n\u001b[32m     42\u001b[39m             sargs = \u001b[38;5;28mself\u001b[39m, *args\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "simple_model = (\n",
    "    DPTDepthModel(\n",
    "        scale=0.000305,\n",
    "        shift=0.1378,\n",
    "        invert=True,\n",
    "        backbone=\"vitb_rn50_384\",\n",
    "        non_negative=True,\n",
    "        enable_attention_hooks=False,\n",
    "    )\n",
    "    .float()\n",
    "    .to(\"mps\")\n",
    ")\n",
    "optim = Adam(simple_model.named_parameters(), lr=1e-6)\n",
    "\n",
    "# standard training - no regularization at all\n",
    "train_simple(\n",
    "    model=simple_model,\n",
    "    loader=nyu_train_dataloader,\n",
    "    optim=optim,\n",
    "    epochs=1,\n",
    ")\n",
    "simple_res = eval(simple_model, nyu_test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2026f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_test_frames(simple_model, nyu_test_ds, indices=[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f154840",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutmix_model = DPTDepthModel().float().to(\"mps\")\n",
    "optim = Adam(cutmix_model.parameters(), lr=0.01)\n",
    "\n",
    "# training of cutmix model\n",
    "train_with_cutmix(\n",
    "    model=cutmix_model, loader=nyu_train_dataloader, optim=optim, epochs=1\n",
    ")\n",
    "cutmix_res = eval(cutmix_model, nyu_test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edef5b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model with LMR regularization\n",
    "lmr_model = DPTDepthModel().float().to(\"mps\")\n",
    "optim = Adam(cutmix_model.parameters(), lr=0.01)\n",
    "\n",
    "# training of cutmix model\n",
    "train_with_lmr(model=lmr_model, loader=nyu_train_dataloader, optim=optim, epochs=1)\n",
    "lmr_res = eval(lmr_model, nyu_test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mde",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
